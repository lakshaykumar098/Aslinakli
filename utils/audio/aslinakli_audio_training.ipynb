{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273c502c",
   "metadata": {
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1755977501247,
     "user": {
      "displayName": "Skull Crusher",
      "userId": "14371410655278520423"
     },
     "user_tz": -330
    },
    "id": "273c502c"
   },
   "outputs": [],
   "source": [
    "# ----- Cell 2: Config -----\n",
    "import os, random\n",
    "from glob import glob\n",
    "\n",
    "DATA_DIR = \"C:\\\\Users\\\\laksh\\\\Desktop\\\\Visual Code\\\\Aslinakli\\\\data\\\\audio\"\n",
    "SUBSET_SIZE = 5000      # instead of 500\n",
    "TRAIN_SPLIT = 0.85\n",
    "SAMPLE_RATE = 16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe5ab24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1755977504132,
     "user": {
      "displayName": "Skull Crusher",
      "userId": "14371410655278520423"
     },
     "user_tz": -330
    },
    "id": "cfe5ab24",
    "outputId": "5d2a7f6b-0bf3-4307-a8de-3889cc96022e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 5000 | Real: 2506, Fake: 2494\n"
     ]
    }
   ],
   "source": [
    "# ----- Cell 3: Subset + Split ----\n",
    "\n",
    "# Match real and fake files under any language folder\n",
    "all_files = glob(os.path.join(DATA_DIR, \"*\", \"real\", \"*.wav\")) + \\\n",
    "            glob(os.path.join(DATA_DIR, \"*\", \"fake\", \"*.wav\"))\n",
    "\n",
    "# Shuffle and select subset\n",
    "random.shuffle(all_files)\n",
    "subset_files = all_files[:SUBSET_SIZE]\n",
    "\n",
    "# Train-test split\n",
    "split_index = int(len(subset_files) * TRAIN_SPLIT)\n",
    "train_files = subset_files[:split_index]\n",
    "test_files  = subset_files[split_index:]\n",
    "\n",
    "# ----- Class balance check -----\n",
    "num_real = sum(\"real\" in f for f in subset_files)\n",
    "num_fake = sum(\"fake\" in f for f in subset_files)\n",
    "print(f\"Subset size: {len(subset_files)} | Real: {num_real}, Fake: {num_fake}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e022e7",
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1755977510423,
     "user": {
      "displayName": "Skull Crusher",
      "userId": "14371410655278520423"
     },
     "user_tz": -330
    },
    "id": "24e022e7"
   },
   "outputs": [],
   "source": [
    "#Cell 4\n",
    "\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, files, sr=SAMPLE_RATE):\n",
    "        self.files = files\n",
    "        self.sr    = sr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path  = self.files[idx]\n",
    "        label = 1 if \"/real/\" in path else 0\n",
    "        sig, _ = torchaudio.load(path)\n",
    "        return sig[0], label\n",
    "\n",
    "# drop_last=True prevents small 1-sample batches (which break ECAPA)\n",
    "train_loader = DataLoader(AudioDataset(train_files), batch_size=8, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(AudioDataset(test_files),  batch_size=8, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf3bafa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8906,
     "status": "ok",
     "timestamp": 1755977522314,
     "user": {
      "displayName": "Skull Crusher",
      "userId": "14371410655278520423"
     },
     "user_tz": -330
    },
    "id": "ebf3bafa",
    "outputId": "af2f6263-d679-49f1-8d58-978a6f0529e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laksh\\Desktop\\Visual Code\\Aslinakli\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\laksh\\Desktop\\Visual Code\\Aslinakli\\venv\\lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "c:\\Users\\laksh\\Desktop\\Visual Code\\Aslinakli\\venv\\lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "c:\\Users\\laksh\\Desktop\\Visual Code\\Aslinakli\\venv\\lib\\site-packages\\speechbrain\\utils\\autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "C:\\Users\\laksh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    }
   ],
   "source": [
    "# ----- Cell 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from speechbrain.inference import EncoderClassifier\n",
    "\n",
    "sb_model = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "# Replace last classifier layer with 2-class layer\n",
    "in_dim = sb_model.mods.classifier.weight.shape[1]\n",
    "sb_model.mods.classifier = nn.Linear(in_dim, 2)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sb_model = sb_model.to(device)\n",
    "\n",
    "#  üîß Updated optimizer with lower learning rate\n",
    "optimizer = torch.optim.Adam(sb_model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd057a23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21211800,
     "status": "ok",
     "timestamp": 1755998738004,
     "user": {
      "displayName": "Skull Crusher",
      "userId": "14371410655278520423"
     },
     "user_tz": -330
    },
    "id": "bd057a23",
    "outputId": "8453e008-e327-4daa-a1a0-cd80a4341431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/531 [00:00<?, ?it/s]c:\\Users\\laksh\\Desktop\\Visual Code\\Aslinakli\\venv\\lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "CategoricalEncoder.expect_len was never called: assuming category count of 7205 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 1 | Train Loss: 5.1619\n",
      "\n",
      "üîÅ Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 2 | Train Loss: 2.9960\n",
      "\n",
      "üîÅ Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 3 | Train Loss: 1.9082\n",
      "\n",
      "üîÅ Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 4 | Train Loss: 1.2739\n",
      "\n",
      "üîÅ Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 5 | Train Loss: 0.8856\n",
      "\n",
      "üîÅ Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 6 | Train Loss: 0.6461\n",
      "\n",
      "üîÅ Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 7 | Train Loss: 0.4873\n",
      "\n",
      "üîÅ Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 8 | Train Loss: 0.3951\n",
      "\n",
      "üîÅ Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 9 | Train Loss: 0.3355\n",
      "\n",
      "üîÅ Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 10 | Train Loss: 0.3004\n",
      "\n",
      "üîÅ Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 11 | Train Loss: 0.2762\n",
      "\n",
      "üîÅ Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 12 | Train Loss: 0.2553\n",
      "\n",
      "üîÅ Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 13 | Train Loss: 0.2353\n",
      "\n",
      "üîÅ Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 14 | Train Loss: 0.2192\n",
      "\n",
      "üîÅ Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 15 | Train Loss: 0.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Add this import at the top of your notebook if not already\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(sb_model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    sb_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    print(f\"\\nüîÅ Epoch {epoch+1}/{epochs}\")\n",
    "    for wav, y in tqdm(train_loader, desc=f\"Training\", leave=False):\n",
    "        wav = wav.to(device)\n",
    "        y   = y.to(device)\n",
    "\n",
    "        out = sb_model(wav)\n",
    "\n",
    "        if isinstance(out, tuple):\n",
    "            logits = out[0]\n",
    "        else:\n",
    "            logits = out\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"‚úÖ Epoch {epoch+1} | Train Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa088f7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 507257,
     "status": "ok",
     "timestamp": 1756002996212,
     "user": {
      "displayName": "Skull Crusher",
      "userId": "14371410655278520423"
     },
     "user_tz": -330
    },
    "id": "aa088f7a",
    "outputId": "e2906803-1aad-4110-bdc8-4bbf95d9a85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.06%\n"
     ]
    }
   ],
   "source": [
    "sb_model.eval()\n",
    "correct = 0; total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for wav, y in test_loader:\n",
    "        wav = wav.to(device)\n",
    "        y   = y.to(device)\n",
    "\n",
    "        out = sb_model(wav)\n",
    "        logits = out[0] if isinstance(out, tuple) else out\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        correct += (preds == y).sum().item()\n",
    "        total   += y.size(0)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22066d3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5811,
     "status": "ok",
     "timestamp": 1756003083189,
     "user": {
      "displayName": "Skull Crusher",
      "userId": "14371410655278520423"
     },
     "user_tz": -330
    },
    "id": "22066d3e",
    "outputId": "f2f1e7c7-36a5-494f-e2f1-f69db0887f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: Rawnetlite_Model_Output.pt\n",
      "Log entry added: 2025-08-25 00:01:47,5,99.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "model_path = \"models/Rawnetlite_Model_Output.pt\"\n",
    "torch.save(sb_model, model_path)\n",
    "print(\"Model saved to:\", model_path)\n",
    "\n",
    "log_path = \"utils/Audio_training_logs.csv\"\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "log_row = f\"{timestamp},5,{test_acc:.2f}\\n\"\n",
    "\n",
    "with open(log_path, \"a\") as log_file:\n",
    "    log_file.write(log_row)\n",
    "\n",
    "print(\"Log entry added:\", log_row)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
